{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5659350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from model import MedicalImageCNN, CNNToRNA,CNNClassifier, train_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from helper import collate_fn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140833e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model_auc(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _, labels, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()  # ensure labels are class indices\n",
    "\n",
    "            outputs = model(images)  # shape: [B, num_classes]\n",
    "            probs = F.softmax(outputs, dim=1)  # shape: [B, num_classes]\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_targets.append(labels.cpu())\n",
    "\n",
    "    probs = torch.cat(all_probs).numpy()   # shape: [N, num_classes]\n",
    "    targets = torch.cat(all_targets).numpy().squeeze()  # shape: [N]\n",
    "\n",
    "    if len(probs.shape) != 2:\n",
    "        raise ValueError(f\"Predicted probabilities must be a 2D array. Got shape: {probs.shape}\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(f\"Targets must be a 1D array. Got shape: {targets.shape}\")\n",
    "\n",
    "    try:\n",
    "        # Use multi_class only if more than 2 classes\n",
    "        if probs.shape[1] == 2:\n",
    "            auc = roc_auc_score(targets, probs[:, 1])  # class 1 probability\n",
    "        else:\n",
    "            auc = roc_auc_score(targets, probs, multi_class='ovo', average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating AUC: {e}\")\n",
    "        auc = None \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf0b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 genes:\n",
      "Error calculating AUC: y should be a 1d array, got an array of shape (20, 2) instead.\n",
      "ORAI2 0.2984073036595395 nan\n",
      "Error calculating AUC: y should be a 1d array, got an array of shape (20, 2) instead.\n",
      "DNAL1 0.3143503289473684 nan\n",
      "Error calculating AUC: y should be a 1d array, got an array of shape (20, 2) instead.\n",
      "CHD7 0.4294240851151316 nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 genes:\")\n",
    "\n",
    "#load the gene performance data from the saved file\n",
    "if not os.path.exists('gene_performance.pth'):\n",
    "    raise FileNotFoundError(\"The file 'gene_performance.pth' does not exist.\")\n",
    "gene_performance = torch.load('gene_performance.pth', weights_only=False)\n",
    "gene_performance = dict(sorted(gene_performance.items(), key=lambda item: item[1]['total_lost']))\n",
    "\n",
    "\n",
    "#sort by total_lost in descending order\n",
    "\n",
    "\n",
    "for gene in gene_performance.keys():\n",
    "    #recalculate the test accuracy\n",
    "    model = gene_performance[gene]['model']\n",
    "    model.to(device)\n",
    "    test_loader = DataLoader(gene_performance[gene]['test_dataset'], batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "    gene_performance[gene]['test_accuracy'] = evaluate_model_auc(gene_performance[gene]['model'], test_loader, device)\n",
    "    print(gene, gene_performance[gene]['total_lost'], gene_performance[gene]['test_accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
